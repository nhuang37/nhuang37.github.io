<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Representation Learning | Teresa&#39;s homepage</title>
    <link>https://nhuang37.github.io/tags/representation-learning/</link>
      <atom:link href="https://nhuang37.github.io/tags/representation-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Representation Learning</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 24 Sep 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://nhuang37.github.io/img/icon-192.png</url>
      <title>Representation Learning</title>
      <link>https://nhuang37.github.io/tags/representation-learning/</link>
    </image>
    
    <item>
      <title>From Local to Global: Spectral-Inspired Graph Neural Networks </title>
      <link>https://nhuang37.github.io/publication/spectral/</link>
      <pubDate>Sat, 24 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://nhuang37.github.io/publication/spectral/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Simple Spectral Failure Mode for Graph Convolutional Networks</title>
      <link>https://nhuang37.github.io/publication/gcn/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://nhuang37.github.io/publication/gcn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning Robust Multimodal Knowledge Graph Representations</title>
      <link>https://nhuang37.github.io/publication/multimodalkb/</link>
      <pubDate>Wed, 07 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://nhuang37.github.io/publication/multimodalkb/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Topic Modelling with Latent Dirichlet Allocation (LDA) on Wikipedia Articles</title>
      <link>https://nhuang37.github.io/project/lda/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://nhuang37.github.io/project/lda/</guid>
      <description>&lt;iframe width=&#34;1200&#34; height=&#34;900&#34; name=&#34;iframe&#34; src=&#34;https://raw.githack.com/nhuang37/academic-kickstart/master/content/project/LDA/LDAvis_all.html&#34; frameborder=&#34;0&#34; &gt;&lt;/iframe&gt;
&lt;p&gt;Here is an interactive dashboard showing the learned 45 topics from 33k Wikipedia articles. You can slightly scroll to the right to view the full picture. The left hand side illustrates the topic clusters projected in 2-dimensional space, while the right hand side lists the top terms associated with each topic. You can hover over each topic cluster (left) and view its corresponding most frequent words.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Chatbot</title>
      <link>https://nhuang37.github.io/project/chat/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://nhuang37.github.io/project/chat/</guid>
      <description>&lt;p&gt;An interactive chatbot built with RNN-based Encoder/Decoder. Decoding strategy is based on N-gram blocking for beam search. Have fun chatting :) !&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Matrix Completion for Different Missing Data Patterns</title>
      <link>https://nhuang37.github.io/project/matrix/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://nhuang37.github.io/project/matrix/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;Matrix completion and imputation is a common problem and an important cornerstone in data science applications. We compare the performance of three matrix imputation methods (Soft-Impute, SoftImpute-concat, Multiple Imputation) on different types of missing data patterns using both synthetic and real datasets. Although no method is found to perform significantly better under all circumstances, SoftImpute-concat indeed outperforms original SoftImpute when missing is not at random (NMAR) on our data. Besides, SoftImpute-concat has more robust performance than SoftImpute when missing rate increases. However, no theoretical proof of SoftImpute-concat superior performance under NMAR setting is given so far. Therefore, we discuss possible reasons based on a toy example.&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Simulated Data&lt;/li&gt;
&lt;li&gt;The MovieLens small dataset includes 100,000 ratings (ranging from 0.5 to 5) of 9000 movies by 600 users&lt;/li&gt;
&lt;li&gt;EMBARC study, an 8-week randomized placebo-controlled clinical trial of sertraline enrolled about 300 patients with Major Depressive Disorder&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;algorithm&#34;&gt;Algorithm&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;SoftImpute&lt;/li&gt;
&lt;li&gt;SoftImpute-Concat&lt;/li&gt;
&lt;li&gt;Multiple Imputation&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>
